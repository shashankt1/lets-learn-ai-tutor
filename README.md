# ğŸ§  Let's Learn - AI Tutor

A personalized AI-powered tutoring assistant built with **FastAPI**, **Streamlit**, **Whisper**, **ChromaDB**, and **LLaMA/Mistral**, designed to help students learn better by asking questions via text or audio â€” tailored to their age and understanding level.

---

## ğŸš€ Features

- ğŸ“ Upload learning material (PDF, TXT, MP3, WAV, M4A)
- ğŸ” Converts audio to text using **Whisper**
- ğŸ§  Retrieves context using **ChromaDB + Sentence Transformers**
- ğŸ’¬ Answers based on studentâ€™s **age and learning level**
- ğŸ—£ï¸ Accepts both **text and voice questions**
- ğŸ›ï¸ Built with modular backend (FastAPI) and clean frontend (Streamlit)
- ğŸ’¾ Local vector store using **FAISS** and **Pickle**
- ğŸŒ CORS-enabled and ready for deployment

---

## ğŸ–¼ï¸ Project Structure

lets-learn/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI backend routes
â”‚ â”œâ”€â”€ agent.py # RAG + prompt building logic
â”‚ â”œâ”€â”€ file_processor.py # File parsing and chunking
â”‚ â”œâ”€â”€ whisper_transcriber.py # Whisper audio transcriber
â”‚ â””â”€â”€ mistral_loader.py # LLM wrapper (e.g., Mistral, LLaMA)
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ app.py # Streamlit frontend
â”‚
â”œâ”€â”€ vectorstore/
â”‚ â”œâ”€â”€ index.faiss # FAISS vector DB
â”‚ â””â”€â”€ index.pkl # Chunk metadata
â”‚
â”œâ”€â”€ db/
â”‚ â””â”€â”€ db_handler.py # Log uploads / SQLite setup
â”‚
â”œâ”€â”€ data/uploads/ # Uploaded learning material
â”‚
â”œâ”€â”€ memory.json # Optional memory/log file
â”œâ”€â”€ .env # API keys or environment variables
â””â”€â”€ README.md # You're here.

yaml
Copy
Edit

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/shashankt1/lets-learn-ai-tutor.git
cd lets-learn-ai-tutor
2. Create virtual environment & install dependencies
bash
Copy
Edit
python -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
3. Run FastAPI backend
bash
Copy
Edit
cd backend
uvicorn main:app --reload --port 8010
4. Run Streamlit frontend
bash
Copy
Edit
cd ../frontend
streamlit run app.py
ğŸ“¦ Dependencies
fastapi, uvicorn

streamlit

openai-whisper

sentence-transformers

faiss-cpu

pydantic, requests, python-multipart

sqlite3 (for upload tracking)

ğŸ’¡ How It Works
Upload Material: PDFs and audio are converted to text and chunked.

Embed Chunks: Stored in FAISS with metadata.

Ask Question: User submits a question + age.

Retrieve & Answer: Relevant chunks are retrieved, styled prompt is built, and LLM answers it accordingly.

ğŸ“š Use Cases
AI tutor for school students

Educational chatbot in classrooms

Voice-based learning assistant

Personal study assistant for kids

ğŸ“Œ TODO / Improvements
âœ… Audio-to-question flow with Whisper

âœ… Age-based prompt styling

 File deletion + management

 Session history tracking

 Multi-language support

 HuggingFace Spaces / Docker deployment

ğŸ§‘â€ğŸ’» Author
Shashank Tiwari
